{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Desktop\\All projects\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Desktop\\All projects\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Desktop\\All projects\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Desktop\\All projects\\.venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "37/37 [==============================] - 98s 2s/step - loss: 0.0529\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 80s 2s/step - loss: 0.0144\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 80s 2s/step - loss: 0.0116\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 81s 2s/step - loss: 0.0084\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 87s 2s/step - loss: 0.0070\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 87s 2s/step - loss: 0.0062\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 81s 2s/step - loss: 0.0057\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 78s 2s/step - loss: 0.0054\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 78s 2s/step - loss: 0.0050\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 80s 2s/step - loss: 0.0046\n",
      "37/37 [==============================] - 7s 86ms/step\n",
      "Silhouette Score (Autoencoder): 0.37035838\n",
      "Cluster 1\n",
      "Cluster 2\n",
      "Cluster 3\n",
      "Cluster 4\n",
      "Cluster 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Path to the folder containing your images\n",
    "folder_path = \"E7-images\"\n",
    "\n",
    "# Initialize a list to store the loaded images\n",
    "images = []\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is an image (JPEG or PNG)\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "        # Construct the full path to the image file\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the image\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        # Append the image to the list\n",
    "        images.append(image)\n",
    "\n",
    "# Flatten images\n",
    "flattened_images = np.array([image.flatten() for image in images])\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "flattened_images = flattened_images / 255.0\n",
    "\n",
    "# Define and train the autoencoder\n",
    "autoencoder = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(flattened_images.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(flattened_images.shape[1], activation='sigmoid')\n",
    "])\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(flattened_images, flattened_images, epochs=10, batch_size=32)\n",
    "\n",
    "# Extract features using the encoder part\n",
    "encoder = Sequential(autoencoder.layers[:3])\n",
    "autoencoder_features = encoder.predict(flattened_images)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(autoencoder_features)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Evaluate clustering\n",
    "silhouette_avg_autoencoder = silhouette_score(autoencoder_features, labels)\n",
    "print(\"Silhouette Score (Autoencoder):\", silhouette_avg_autoencoder)\n",
    "\n",
    "# Group samples by cluster\n",
    "cluster_samples_autoencoder = [[] for _ in range(5)]\n",
    "for idx, label in enumerate(labels):\n",
    "    cluster_samples_autoencoder[label].append(images[idx])\n",
    "\n",
    "# Print 5 randomly picked samples from each cluster\n",
    "for cluster_idx, samples in enumerate(cluster_samples_autoencoder):\n",
    "    print(\"Cluster\", cluster_idx + 1)\n",
    "    random_samples = random.sample(samples, min(5, len(samples)))\n",
    "    for i, sample in enumerate(random_samples):\n",
    "        cv2.imshow(f\"Cluster {cluster_idx + 1} Sample {i + 1}\", sample)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
