{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data/Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bpadm\\AppData\\Local\\Temp\\ipykernel_37340\\2079432233.py:52: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: tf.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2 #cv2 stands for opencv : opensource computer vision and ml library\n",
    "import numpy as np\n",
    "import os #interacting with operating system- to do things like we use command line for accessing and manipulating files\n",
    "import csv\n",
    "\n",
    "# Path to the folder containing your images\n",
    "folder_path = \"E7-images\"\n",
    "\n",
    "output_folder = \"E7-tfimages\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize lists to store results\n",
    "images =[]\n",
    "tight_fitting_boxes = []\n",
    "contour_areas = []\n",
    "tight_fit_box_areas = []\n",
    "dim_1=[]\n",
    "dim_2=[]\n",
    "\n",
    "processed_images=0\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is an image (JPG OR JPEG or PNG)\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"): #so that we don't run into a situation where we are doing imge kund operations on some non-image files\n",
    "        # Construct the full path to the image file\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path) #reading specific image file\n",
    "        images.append(image)\n",
    "        original_image = image.copy()  # Save a copy for visualization\n",
    "        \n",
    "        # Convert image to grayscale\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #conversion flag- cv2.COLOR_BGR2GRAY\n",
    "        \n",
    "        # Threshold the image to create a mask of colored areas \n",
    "        #threshhold fn gives threshold value and thresholded image as output.\n",
    "        _, masked_image = cv2.threshold(gray_image, 200, 255, cv2.THRESH_BINARY_INV) \n",
    "        # 200 is our threshold value. pixels above 200 get conv into 255(W) and rest into 0(B): then through binary inversion fn they are inverted -- swaped.\n",
    "\n",
    "        # Find contours \n",
    "        #findContours function gives contours and their heirarchies\n",
    "        contours, _ = cv2.findContours(masked_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "        #cv2.RETR_EXTERNAL ignores any internal contours that exist. \n",
    "        #cv2.CHAIN_APPROX_SIMPLE is contour approximation method- compresses horizontal, vertical, and diagonal segments and leaves only their end points.\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Minimum area rectangle\n",
    "            rect = cv2.minAreaRect(contour) #tight-fitting box\n",
    "            \n",
    "            # Box coordinates\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            tight_fitting_boxes.append(box)\n",
    "            \n",
    "            # Calculate dimensions\n",
    "            dim1 = np.linalg.norm(box[0] - box[1])\n",
    "            dim2 = np.linalg.norm(box[1] - box[2])\n",
    "            \n",
    "            dim_1.append(dim1)\n",
    "            dim_2.append(dim2)\n",
    "            # Calculate contour area\n",
    "            contour_area = cv2.contourArea(contour)\n",
    "            contour_areas.append(contour_area)\n",
    "            \n",
    "            # Calculate layout area\n",
    "            tight_fit_box_area = dim1 * dim2\n",
    "            tight_fit_box_areas.append(tight_fit_box_area)\n",
    "            \n",
    "            # Draw tight-fitting box and contours on the image (for visualization)\n",
    "            cv2.drawContours(original_image, [box], 0, (0, 255, 0), 2)  # Tight-fitting box\n",
    "            cv2.drawContours(original_image, [contour], 0, (255, 0, 0), 2)  # Contour\n",
    "        \n",
    "        # Write processed image to output folder\n",
    "        output_img_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_img_path, original_image)\n",
    "        ##### sample print block #####\n",
    "        # # Show the image with tight-fitting boxes and contours (for visualization)\n",
    "        # cv2.imshow(\"Image with Tight-Fitting Boxes and Contours\", original_image)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        \n",
    "        # Increment the counter\n",
    "        processed_images += 1\n",
    "        \n",
    "        # Stop after processing 5 images ##### sample print block #####\n",
    "        # if processed_images == 5:\n",
    "        #     break\n",
    "csv_file = \"tf.csv\"\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Tight-Fitting Boxes (Coordinates)\", \"Dimension 1\", \"Dimension 2\", \"Contour Area\", \"Tight fit box Area\"])\n",
    "    for i in range(len(tight_fitting_boxes)):\n",
    "        writer.writerow([tight_fitting_boxes[i], dim_1[i], dim_2[i], contour_areas[i], tight_fit_box_areas[i]])\n",
    "\n",
    "print(\"Results saved to:\", csv_file)\n",
    "\n",
    "# # Print 5 samples of results  ##### sample print block #####\n",
    "# for i in range(5):\n",
    "#     print(\"Sample\", i+1, \"Tight-Fitting Boxes (Coordinates):\", tight_fitting_boxes[i])\n",
    "#     print(\"Sample\", i+1, \"Dimension 1:\", dim_1[i])\n",
    "#     print(\"Sample\", i+1, \"Dimension 2:\", dim_2[i])\n",
    "#     print(\"Sample\", i+1, \"Contour Area:\", contour_areas[i])\n",
    "#     print(\"Sample\", i+1, \"Tight fit box Area:\", tight_fit_box_areas[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping based on shapes -- autoencoders and k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Flatten images\n",
    "flattened_images = np.array([image.flatten() for image in images])\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "flattened_images = flattened_images / 255.0\n",
    "\n",
    "# Define and train the autoencoder\n",
    "autoencoder = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(flattened_images.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(flattened_images.shape[1], activation='sigmoid')\n",
    "])\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(flattened_images, flattened_images, epochs=10, batch_size=32)\n",
    "\n",
    "# Extract features using the encoder part\n",
    "encoder = Sequential(autoencoder.layers[:3])\n",
    "autoencoder_features = encoder.predict(flattened_images)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(autoencoder_features)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Evaluate clustering\n",
    "silhouette_avg_autoencoder = silhouette_score(autoencoder_features, labels)\n",
    "print(\"Silhouette Score (Autoencoder):\", silhouette_avg_autoencoder)\n",
    "\n",
    "# Group samples by cluster\n",
    "cluster_samples_autoencoder = [[] for _ in range(5)]\n",
    "for idx, label in enumerate(labels):\n",
    "    cluster_samples_autoencoder[label].append(images[idx])\n",
    "\n",
    "# Print 5 randomly picked samples from each cluster\n",
    "for cluster_idx, samples in enumerate(cluster_samples_autoencoder):\n",
    "    print(\"Cluster\", cluster_idx + 1)\n",
    "    random_samples = random.sample(samples, min(5, len(samples)))\n",
    "    for i, sample in enumerate(random_samples):\n",
    "        cv2.imshow(f\"Cluster {cluster_idx + 1} Sample {i + 1}\", sample)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
